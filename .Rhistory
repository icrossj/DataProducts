plot(ToothGrowth$dose,ToothGrowth$len)
ToothGrowth
split(ToothGrowth)
split(ToothGrowth,factor)
OJgroup <- ToothGrowth[supp == "OJ",]
OJgroup <- ToothGrowth[ToothGrowthsupp == "OJ",]
OJgroup <- ToothGrowth[ToothGrowth$supp == "OJ",]
OJgroup
plot(OJgroup$dose,OJgroup$len)
?plot
plot(ToothGrowth$dose,ToothGrowth$len,type="n")
point(ToothGrowth$dose,ToothGrowth$len)
plot(ToothGrowth$dose,ToothGrowth$len)
?point
?points
plot(ToothGrowth$dose,ToothGrowth$len,type="n")
points(ToothGrowth$dose,ToothGrowth$len)
points(ToothGrowth$dose,ToothGrowth$len,col="blue")
vc <- ToothGrowth$len[ToothGrowth$supp == "VC" & ToothGrowth$dose == 0.5,]
vc <- ToothGrowth$len[ToothGrowth$supp == "VC" & ToothGrowth$dose == 0.5]
vc
mtcars
mpg1 <- mtcars[am == "0",]
mpg1 <- mtcars[mtcars$am == "0",]
mpg2 <- mtcars[mtcars$am == "1",]
plot(mtcars$am,mtcars$mpg)
mpg1
mtcars
m4 <- mtcars[mtcars$cyl == 4]
m4 <- mtcars[mtcars$cyl == 4,]
m4
plot(m4$am,m4$mpg)
m6 <- mtcars[mtcars$cyl == 6,]
plot(m6$am,m6$mpg)
unique(mtcars$cyl)
length(unique(mtcars$cyl))
m8 <- mtcars[mtcars$cyl == 8,]
fit <- lm(mpg ~ am, data = mtcars)
coef(fit)
plot(fit)
plot(fit)
plot(predict(fit),resid(fit),pch = '.')
plot(predict(fit),resid(fit))
mean(mpg1$mpg)
mean(mpg2$mpg)
mean(mpg2$mpg) - mean(mpg1$mpg)
plot(mtcars$am,mtcars$mpg,pch=19,col="darkgrey")
glm1 <- glm(mtcars$mpg ~ mtcars$am, family="poisson")
warnings()
?glm
glm1 <- glm(mtcars$mpg ~ mtcars$am, family="binomial")
fit <- lm(mpg ~ am, data = mtcars)
coef(fit)
storm_data <- read.csv("repdata-data-StormData.csv.bz2")
save(storm_data,file="stormbackup.RData")
load("stormbackup.RData")
head(storm_data)
unique(storm_data$EVTYPE)
xmlParse("chart1.xml")
library(XML)
xmlParse("chart1.xml")
doc <- xmlParse("chart1.xml")
dataDictionary <- xmlToDataFrame(getNodeSet(doc1,"//attr"))[c("xVal","yVal")]
dataDictionary <- xmlToDataFrame(getNodeSet(doc,"//attr"))[c("xVal","yVal")]
write(doc,"test1")
doc
cat(doc)
?XML
doc <- xmlParse("chart1.xml",useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[2]]
rootNode[[3]]
rootNode[[1]][[1]]
rootNode[[1]]
rootNode[[2]]
rootNode[[3]]
rootNode[[4]]
rootNode[[5]]
rootNode[[6]]
rootNode[[7]]
rootNode[[8]]
rootNode[8]
rootNode[9]
rootNode[6]
rootNode[1]
rootNode[2]
rootNode[3]
rootNode[4]
rootNode[5]
rootNode[5]
rootNode[6]
rootNode[[6]
]
rootNode[[5]][[1]]
rootNode[[5]][[2]]
rootNode[[5]][[3]]
rootNode[[5]][[4]]
rootNode[[5]][[5]
]
rootNode[[5]][[6]]
rootNode[[5]][[7]]
rootNode[[5]][[8]]
rootNode[[5]][[3]]
rootNode[[5]][[3]][[1]]
rootNode[[5]][[3]][[2]]
rootNode[[5]][[3]][[2]][[1]]
rootNode[[5]][[3]][[2]][[2]]
rootNode[[5]][[3]][[2]][[3]]
rootNode[[5]][[3]][[2]][[3]][[1]]
rootNode[[5]][[3]][[2]][[3]][[2]]
rootNode[[5]][[3]][[2]][[3]][[3]]
rootNode[[5]][[3]][[2]][[3]][[4]]
rootNode[[5]][[3]][[2]][[3]][[5]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[1]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[1]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[2]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[3]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[4]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[5]]
rootNode[[5]][[3]][[2]][[3]][[5]][[1]][[2]][[6]]
?xmlSApply
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(rCharts)
install.packages("devtools")
install_github("ramnathv/rCharts@dev")
library(devtools)
install_github("ramnathv/rCharts@dev")
find_rtools()
find_rtools()
install_github("ramnathv/rCharts@dev")
install.packages("base64enc")
install_github("ramnathv/rCharts@dev")
library(rCharts)
library(airquality)
airquality
dTable(airquality, sPaginationType = "full_numbers")
install.packages("shiny")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(caret)
install.packages("caret")
install.packages("kernlab")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
spam
inTrani <- createDataPartition(y=spam$time, p=0.75,list=FALSE)
inTrani <- createDataPartition(y=spam$type, p=0.75,list=FALSE)
set.seed(32343)
modelFit <- train(type ~., data=training, method="glm")
install.packages("e1071")
modelFit <- train(type ~., data=training, method="glm")
modelFit
modelFit$finalModel
predictions <- predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=FALSE)
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
folds <- createResample(y=spam$type,times=10,list=TRUE)
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
tme <- 1:1000
folds <- createTimeSlices(y=tme,initialWindow=20,horizon=10)
names(folds)
folds$train[[1]]
folds$test[[1]]
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~., data = training, method = "glm")
args(train.default)
args(trainControl)
set.seed(1235)
modelFit <- train(type ~.,data = training, method = "glm")
modelFit3
modelFit
libarry(ISLR); library(ggplot2); library(caret)
library(ISLR); library(ggplot2); library(caret)
install.packages("ISLR")
library(ISLR)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,color=jobclass,data=training)
qq <- qplot(age,wage,color=education,data=training)
qq + geom_smooth(method = 'lm',formula=y~x)
cutWage <- cut2(training$wage,g=3)
install.packages("Hmisc")
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
p1
p2 <- qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot","jitter"))
grid.arragneg(p1,p2,ncol=2)
grid.arrange(p1,p2,ncol=2)
install.packages("gridExtra")
library(gridExtra)
grid.arrange(p1,p2,ncol=2)
t1 <- table(cutWage,training$jobclass)
t1
prop.table(t1,1)
qplot(wage,color=education,data=training,geom="density")
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
tarining <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$captitalAve,main="",xlab="ave. capital run length")
hist(training$capitalAve,main="",xlab="ave. capital run length")
training <- spam[inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve
)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data = training, preProcess=c("center","scale"),method="glm")
modelFit
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
par(mfrow=c(1,2))
hist(trainCapAveS)
qqnorm(trainCapAveS)
set.seed(13343)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
capAve <- predict(preObj,training[,-58])$capAve
install.packages("RANN")
library(RANN)
capAve <- predict(preObj,training[,-58])$capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve-capAveTruth)
quantile((capAve - capAveTreth)[selectNA])
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
library(kernlab); data(spam)
spam$capitalAveSq <- spam$capitalAve^2
spam$capitalAve^2
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,];testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
lm1 <- lm(wage ~bsBasis,data = training)
plot(tarining$age,training$wage,pch=19,cex=0.5)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
predict(bsBasis, age=testing$age)
library(caret)
library(kernlab)
data(spam)
inTrain <_ createDataPartition(y=spam$type,p=0.75,list=FALSE)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
x <- 0.71*training$num415 + 0.71*training$num857
y <- 0.71*training$num415 - 0.71*training$num857
plot(x,y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1+1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
names(spam)
spam[,-58]
names(spam)
head(spam[,-58])
head(spam[,58])
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~.,method = "glm", data = trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <-train(testing$type~.,method="glm",preProcess="pca",data=training)
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
library(caret);
data(faithful)
set.seed(333)
inTrain <- createDataParition(y=faithful$waiting, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,];
testFaith <- faithful[-inTrain,]
head(trainFaith)
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,];
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waiting",ylab="duration")
lm1 <- lm(eruptions ~ waiting, data=trainFaith)
summary(lm1)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1]+coef(lm1)[2]*80
newdaat <- data.frame(waiting=80)
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainingFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waiting",ylab="duration")
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waiting",ylab="duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="waiting",ylab="duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",col=c(1,2,2),lty=c(1,1,1),lwd=3)
modFit <- train(eruptions ~ waiting, data=trainFaith,method="lm")
summary(modFit$finalModel)
library(ISLR)
library(ggplot2)
library(caret);
data(Wage)
Wage <-subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,];
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePLot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,color=jobclass,data=training)
qplot(age,wage,color=education,data=training)
modFit <- train(wage ~ age+jobclass+edication,method = "lm",data=training)
modFit <- train(wage ~ age+jobclass+education,method = "lm",data=training)
finMod <-modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,color=race,data=training)
plot(finMod$residuals,pch=19)
pred <- predict(modFit,testing)
qplot(wage,pred,color=year,data=testing)
modFitAll <- train(wage ~.,data=training, method="lm")
pred <- predict(modFitAll,testing)
qplot(wage,pred,data=testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
dim(training); dim(testing)
install_github('slidify','ramnathv')
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training=mixtures[inTrain,]
testing=mixtures[-inTrain,]
?cut2
library(Hmisc)
?cut2
names <- colnames(concrete)
names
names <_ names[-length(names)]
names <- names[-length(names)]
names
featurePlot(x = training[,names],y=training$CompressiveStrength,plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x=index,y=CompressiveStrength))+geom_point()+theme_bw()
cutCS <- cut2(training$CompressiveStrength, g=4)
summary(cutCS)
ggplot(data = training, aes(y=index, x= cutCS))+geom_boxplot()+geom_jitter(col="blue")+theme_bw()
featurePlot(x = training[,names],y=cutCS,plot="box")
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram()+theme_bw()
ggplot(data = training, aes(x = log(Superplasticizer+1)) + geom_histogram()+theme_bw()
ggplot(data = training, aes(x = log(Superplasticizer+1)) + geom_histogram()+theme_bw()
ggplot(data = training, aes(x = log(Superplasticizer+1))) + geom_histogram()+theme_bw()
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram()+theme_bw()
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram()+theme_bw()
Superplasticizer
training$Superplasticizer
training$Superplasticizer[1]
training$Superplasticizer[2]
training$Superplasticizer[3]
training$Superplasticizer[4]
training$Superplasticizer[766]
log(training$Superplasticizer[766])
log(training$Superplasticizer[766]+1)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,p=3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL",colnames(training),value=TRUE)
preProc <- preProcess(training[,IL_str],method="pca",thresh=0.9)
preProc$rotation
preProc <- preProcess(training[,IL_str],method="pca",thresh=0.8)
preProc$rotation
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL_str <- grep("^IL",colnames(training),value=TRUE)
predictors_IL <- predictors[,IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p=3/4)[[1]]
training = df[inTrain,]
testing = df[-inTrain,]
modelFit <_ train(diganosis ~., method = "glm",data=training)
modelFit <- train(diganosis ~., method = "glm",data=training)
modelFit <- train(diagnosis ~., method = "glm",data=training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
getwd()
setwd("C:/Users/Marvin/Desktop/coursera/DataProducts")
getwd()
runApp()
library(shiny)
library(shinyapps)
runApp()
deployApp(name="ColorPicker")
deployApp(appname="ColorPicker")
deployApp()
